\input{figs/software.tex}
\chapter{Offline Software and The COMET Simulation}
In 2013 when I first worked on the COMET experiment, there were many disparate stand-alone simulations being run and no unified approach for data structures and analysis.
Since then, a single unified software framework has been prepared and is now being used throughout the collaboration.
Developing this framework has been a large part of my work over the last four years
, so this chapter presents both a summary of the framework and its development as well as an explanation of the techniques used.

\section{Developing the COMET Offline Framework}
Work to produce a common, standardised software framework for COMET began when funding was awarded for \phaseI.
With some four years to go before the switch on, it was clear that the support structure to handle and analyse the data needed to be in place soon.
Given the scale of the project and the available resources, the decision was taken to base the COMET offline framework on an existing one, which would reduce the amount of work needed and improve the reliability of the software since it would have been tested elsewhere.
A requirements document~\cite{COMETSoftwareRequirements} was drawn up with a list of items that the software should be able to do and a survey of existing experiments undertaken to build a list of candidate frameworks.
The list contained:
\begin{description}
\item [art] A framework being developed primarily at Fermilab~\cite{art:2011} which is also being used by Mu2e amongst other experiments.
\item [ND280] The framework~\cite{T2K:nim} used by the near detectors of the T2K experiment, which are also based at J-PARC.
\item [GAUDI] which is used by LHCb amongst other experiments~\cite{gaudi:2001}.
\item [MARLIN] The software being developed for the International Linear Collider (ILC)~\cite{marlin:web}.
\end{description}

The final decision was to use the ND280 framework\footnote{The term `ND280' can
refer to one of either the ND280 detector itself, the site at J-PARC that
houses both the ND280 and INGRID detectors, or the software used to analyse and
simulate the T2K near-detectors.  For the purposes of this chapter, unless
specified explicitly, the term `ND280' should be taken as referring to the
software.} 
since GAUDI and MARLIN would have required to much effort to adapt to the COMET
requirements; since art is used by Mu2e and keeping the software distinct is
important for the two experiments to co-exist as cross-checks; and because the
ND280 software was already known to a large part of the COMET collaboration and
had been tested on real data at J-PARC.

\FigNDTwoEighty
\Fig{software:ND280} shows an overview of the ND280 framework, including its package structure and the various interactions between packages.

With the decision to base the COMET experiment on the ND280 framework -- and with the selection of the new name: `ICEDUST' -- the process of forking the software was begun.
Since the ND280 framework had evolved somewhat organically a review of the conventions and code names was performed.
For example, whilst the ND280 software prefixes all classes with a capital `T', the ICEDUST conventions~\cite{ID:conventions} agreed to swap this to a capital `I' to reduce clashes with ROOT which also uses `T'.
The package renaming scheme~\cite{ID:packageRenaming} was developed so that the purpose of a package and its role with the other packages could be more clearly identified.

Whilst fundamental, low-level packages have been left relatively unchanged higher-level packages which include more detector specific details had to be developed.
Additionally some aspects of COMET needed considerably more support than had been present in the ND280 software.
Some of the key changes that have been introduced between ICEDUST and ND280 are:
\begin{description}
	\item [Simulation] Although the fundamental data types have not been changed, the simulation has been nearly completely rewritten.
		In particular, support for hadron production codes have been added to model the production target;
		both the Geant4-based package (renamed to SimG4) and the detector response simulation (renamed as SimDetectorResponse) were given near-total makeovers;
		a new package (SimHitMerger) for resampling the G4Hits (simulated charge or energy deposits) was added.
		Custom physics models have been added to SimG4 to improve the modelling of the COMET-specific physics processes.
	\item [Magnetic Field handling]  whilst the ND280 detector has a fairly straight-forward magnetic field, the COMET experiment has anything but this.  
		Accordingly significant work has been made to replace the way
		the magnetic field was handled from essentially a few constants
		to the ability to use complete fieldmap descriptions made with
		external field calculation software.
	\item [Geometry handling] The unusual shape of the COMET experiment, the level of detail needed for background estimations in a high-precision experiment, and the changing nature of a staged experiment meant a more elaborate scheme for handling the geometry was necessary than had existed in ND280.
	\item [Reconstruction and Calibration packages] As simply renaming of the packages, the interdependence of the calibration and reconstruction packages has been improved.
		Additionally, support for track fitting using Genfit2~\cite{genfit-Hoppner:2009af} has been added as well as new track finding algorithms being developed.
\end{description}

In addition to the above changes to the way the software runs, the distribution of the software has changed from using CMT~\cite{cmt} with CVS version control to being based on git with a GitLab~\cite{GitLab} web-based user interface for the official repository.
The switch to GitLab also brought a `merge-request' which has allowed development of ICEDUST to progress rapidly with only a small number of developers.
Although initially the intention was also to switch the build system from CMT to CMake~\cite{cmake}, this decision has since been reversed due to improvements in CMT.

In the 3 years since the initial work forking ND280 to produce ICEDUST in summer 2013 some 3,200 commits have edited about two million lines of code in the official version of the framework.
This has been the work of some 25 collaborators whilst about 15 other users have GitLab accounts and use the software.
ICEDUST has been used to run three large Monte Carlo productions, most recently simulating about $10^{11}$~\ac{POT} events -- equivalent to 18,000 \phaseI bunches -- in some 100~TB of simulated data.

\section{Overview of ICEDUST}
ICEDUST Can Efficiently Do Useful Software Things and stands for the Integrated COMET Experiment Data User Software Toolkit.
\Fig{software:ICEDUSTOverview} shows the flow of data through the different packages of the framework and the data formats used.

\FigICEDUSTOverview

Inside the framework, nearly all processing is done using a ROOT file-based format known as oaEvent.  
Files of this type contain header information providing run identification numbers as well as a description of the geometry and magnetic field.  
The data payload contained in oaEvent files is stored in a ROOT TTree with a single branch containing a single COMET event per entry.
Each COMET event has a dynamic structure and can have any object which derives from the IDatum base class added to its list of data on an event-by-event basis.

Data from the detector systems is recorded in MIDAS~\cite{MIDAS} format which also contains data from the slow control monitors such as temperature sensors and high-voltage power supplies.
The task of converting the MIDAS files into the oaEvent format is handled by the package oaUnpack which writes out new, converted files, and oaRawEvent which can convert the MIDAS files to oaEvent format on the fly.

Simulated data is also produced in the oaEvent format and involves some 4 to 6 packages being called, described in more depth in section~\sect{COMETSim}.

Once either simulated data has been produced or real data has been converted, calibration routines can then be applied.
Each sub-detector is capable of pulling constants that were previously generated from a MySQL database and applying these to the detected (or simulated) energy deposits.
These calibrated hits are then passed into the reconstruction stage.  
Here again each sub-detector system is first allowed to handle the data until a full reconstructed event is produced.
For the tracking detectors this stage typically involves an initial track finding stage, where noise hits are removed and track candidates consisting of a list of hits are collected, and secondly a track fitting stage where the actual path of the underlying particle is reconstructed and key values like momentum and helical pitch-angle deduced.

Nearly all of the processing of data up to this stage has used the oaEvent format.
The final analysis stage however moves into a simpler, flatter format, known as oaAnalysis, which produces a data summary tree (as opposed to tape) that can be accessed without a dependence on the full ICEDUST software.

Around all of this there are several utility packages, such as the event display which can visualise any oaEvent file, and IcedustControl which can run a single set of data through the data chain and is the main steering mechanism used for production running.

\section{The COMET Simulation}
\sectlabel{COMETSim}
\FigSimulationOverview
The ability for an experiment to set stringent confidence limits in the event of a null-observation is determined both by the expected signal acceptance (which should be high) and the predicted number of background events (which should be low).
For COMET's target single-event sensitivity -- which is only a measure of the signal efficiency -- to translate to a comparable confidence limit if no signal is observed, fewer than one background events should occur during the run.
By comparison, some $10^{18}$ and $10^{21}$~protons \CHECK{Is this the right number of protons on target?} will impinge the production target in \phaseI and \phaseII respectively so it is clear that the ability to suppress backgrounds must be demonstrably high.

Simulation plays a crucial role in making such a demonstration. 
Before the experiment is built and operated it allows one to optimise crucial aspects of the geometry and parameters, such as the magnetic field strengths or timing cuts.
In addition, using Monte Carlo techniques in an accurate simulation allows an estimation of the background rate by sampling the parameter space corresponding to each stage of the experiment.
Clearly then the simulation itself must be as faithful a reproduction of the true experiment as possible.


The COMET simulation therefore needs to be both highly accurate and highly efficient.
As well as custom physics modelling, and special handling for the magnetic field, several resampling techniques have been introduced to increase the statistical power.
The steps needed to build up the COMET simulation are shown in \fig{software:SimulationOverview}.

To reduce the uncertainties associated with the production target and the muon and pion yield multiple hadron codes can be used, including PHITS~\cite{PHITS2002}, MARS~\cite{MARS1995}, Fluka~\cite{FLUKA2005} and Geant4~\cite{Geant42003}.
The SimG4 package, which is based on Geant4, then takes over the muon beam simulation and tracking of particles to the detectors.
These energy deposits, referred to as G4Hits, can then be converted to realistic electronic detector-readouts by the SimDetectorResponse package.
Often though, the G4Hits are first reshuffled with G4Hits from other events.  
Since one event coming out from SimG4 is 

\subsection{Handling Geometry}
During the change from ND280 to ICEDUST, a new geometry handling scheme was introduced to the SimG4 package.
This change was motivated by: 
    the fact that COMET has a large number of components with a large variety of complexities, shapes and sizes;
    the COMET geometry will change dramatically throughout the lifetime of the experiment;
    all pieces of material closed to the beam could potentially contribute to background rates if, for example, they scatter high energy particles into a high-acceptance region in the phase space.

The aim of the new geometry handling scheme tries to address these issues.
The goals in developing the new were approach were to:
\begin{itemize}
\setlength{\itemsep}{-1ex}
\item define a clear mechanism for how the geometry is implemented and controlled,
\item decouple the code for physically isolated parts of the experiment,
\item provide the flexibility to add and remove parts of the experiment,
\item maximise the maintainability of the code related to geometry,
\item allow for easy inspection of both the geometry and the various parameters that control it.
\end{itemize}

\FigGeometryHeirarchy

The final scheme uses a nested component structure which is built up using compiled c++ to define the volumes hierarchy in a modular way with parameters provided at run-time to define the actual shapes and locations of the volumes.
The run-time parameters are `owned' by the component they are attributed to and can be assigned values using based on the values of other parameters and inspected easily by various print commands.
Access to values of other parameters is given provided they are owned by an accessible component.
Whether or not another component is accessible depends on its relative position of in the component hierarchy: the target component must either be an ancestor, immediate child, or share the same parent component, as demonstrated in \fig{software:componentHeirarchy}.

To provide the value of a parameter, standard, human readable infix notation allows integers, doubles, three-vectors and rotation matrices to be combined and manipulated.
In addition parameters can be easily repeated or indexed, such as for the positions of crystals in the ECAL or straws in a straw tracker plane, where the $i$-th position depends on the value of $i$.
A small demonstration of some valid parameter assignments is shown in \fig{software:geom:paramAssignments}.

Using this scheme, multiple geometries for different stages of COMET have been developed and can be easily swapped between.
Each one is able to re-use much of the code for another, such as the experiment hall building which appears in every geometry.
In addition it has been straight forward to build up significant complexity in key areas such as the production target.
\Fig{software:geometryScreenshots} shows some images of the geometry that has been created using this scheme.

A more thorough description of the geometry scheme  in SimG4 as well as a users guide can be found at \url{www.hep.ph.ic.ac.uk/~bek07/comet/SimG4/documentation/index.shtml}.

Once SimG4 has created the geometry, it writes it out to a ROOT-based format alongside the data, using ROOT's TGeo classes~\cite{ROOTTGeo}.
This is then used by the other packages, such as calibration and analysis.  
The event display also uses this to show the various hits and tracks overlaid on the geometry.

\subsection{Field Calculation}
\begin{easylist}
%# In COMET a static magnetic field is used to capture and disperse charged particles.
%# Bumps in field can mirror particles which will cause delays to particle arrival
%# Need dipole field and solenoid field calculations
# Calculations by Toshiba, and in-house using Opera, Tosca and G4Beamline.
# Handling of fieldmap information in ICEDUST
# Although pure magnetic fields are currently used, electric fields can in principle be added in exactly the same way.
\end{easylist}

An essential aspect of the \COMET experiment is the static magnetic field that is used along the beam line to capture, focus and disperse charged particles.
Modelling this field accurately is important to ensure any outcomes of the simulation are reliable.
In particular, dips in the field have a risk of mirroring particles backwards or even trapping particles for extended periods.
This could be especially dangerous for \COMET since in the process the timing information of the particle is lost which would reduce the efficiency of the timing cut to suppress backgrounds.

Magnetic field calculations can become quite computationally expensive.  
As a result approximations and assumptions are often made to simplify the process, such as the assumption of symmetry about an axis or plane to reduce the effective number of dimensions to the problem.
As well as modelling the electric current flow, material effects must also be accounted for particularly in the yoke and surrounding material of the beamline.
Often these material effects are linear, but in regions of high magnetic field this linearity can be lost via processes such as saturation, further increasing the computational complexity.

There are two distinct types of magnetic field used in COMET, a solenoidal field produced by a winding of super-conducting cable in a spiral, and that of the dipole fields which are produced by a novel winding technique which
is proprietary to Toshiba.  
Although there are several areas of 'bent' solenoid, these are actually formed by a series of smaller straight solenoid sections, and so do not need special treatment in the field calculation.
Straight solenoids are used in many other applications so existing coil calculation methods are reliable. 
Calculating the dipole field however is not so straight forward since the exact configuration is owned by Toshiba.

The COMET collaboration have used several different methods to perform field map calculations.
G4Beamline~\cite{G4Beamline} provides numerous extensions to Geant4 and is able to perform simple solenoid calculations directly.
Whilst it cannot model material effects its speed and simplicity allows quick and simple studies. 
These include full 3D calculations that include material effects using Opera~\cite{Opera} and Tosca~\cite{TOSCA}.

Whilst only magnetic fields have been used in the simulation up to now, ICEDUST is able to handle electric fields in exactly the same way.
For instance future work might see the electric fields for the straw tracker and CDC included to account for the impact of these fields might have on particle scattering in the detector.

\subsection{Production Target Simulations}

\subsection{Extending the Geant4 Physics Modelling}

\subsection{Resampling With the Hit Merger}
